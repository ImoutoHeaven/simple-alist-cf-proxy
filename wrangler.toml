name = "simple-alist-cf-proxy"
main = "dist/worker.js"
compatibility_date = "2024-01-01"

# Environment variables (configure these in Cloudflare Dashboard or use secrets)
# [vars]
# # Origin Encrypt Binding (NEW):
# #   Landing worker now encrypts client origin snapshot (IP / geo / ASN) into additionalInfo.encrypt.
# #   Configure CHECK_ORIGIN below to enforce binding on the download worker, and use skip-origin path actions when needed.
# ADDRESS = "https://your-alist-server.com"
# TOKEN = "your-hmac-token"
# WORKER_ADDRESS = "https://your-worker.workers.dev"
# VERIFY_HEADER = ""
# VERIFY_SECRET = ""
# # ⚠️ NEW: Multi-Authentication Header Support (comma-separated format)
# # You can now specify multiple authentication header/secret pairs for different services
# # Format: "header1,header2,header3"
# # Example for AList + PostgREST:
# #   VERIFY_HEADER = "X-Auth-Token,X-Postgrest-Auth"
# #   VERIFY_SECRET = "alist-secret-key,postgrest-secret-key"
# # Requirements:
# #   - Both arrays must have the same length (if non-empty)
# #   - No spaces between commas: "header1,header2" (spaces will be trimmed automatically)
# #   - All header/secret pairs will be sent in requests to AList API and PostgREST
# # Backward Compatible: Single value still works: VERIFY_HEADER = "X-Auth-Token"
# SIGN_CHECK = "true"
# HASH_CHECK = "true"
# WORKER_CHECK = "true"
# CHECK_ORIGIN = ""              # Comma-separated origin fields: ip, iprange, country, continent, region, city, asn.
#                                # Leave empty to disable binding globally, or use values like "asn" / "country,iprange".
#                                # Pair with the new skip-origin path action for granular overrides.
# ADDITION_CHECK = "true"             # Require additionalInfo and additionalInfoSign, validate signature/path binding
# ADDITION_EXPIRETIME_CHECK = "true"  # Validate expireTime field (only when ADDITION_CHECK is true)
# IPV4_ONLY = "true"
# BLACKLIST_PREFIX = "/private,/admin"
# BLACKLIST_ACTION = "block"
# WHITELIST_PREFIX = "/public"
# WHITELIST_ACTION = "skip-origin"
# EXCEPT_PREFIX = "/api,/system"
# EXCEPT_ACTION = "block-except"
#
# # ⚠️ NEW: Path INCLUDES Matching (Match keywords anywhere in path)
# # In addition to PREFIX (startsWith) matching, you can now use INCLUDES (contains) matching
# # Path is split into: dirPath (folder) + fileName (file name) + fullPath (complete path)
# # Example: "/folder1/folder2/file.txt"
# #   - dirPath: "/folder1/folder2"
# #   - fileName: "file.txt"
# #   - fullPath: "/folder1/folder2/file.txt"
# #
# # INCLUDES matching modes (comma-separated keywords, no spaces):
# BLACKLIST_DIR_INCLUDES = "private,confidential,secret"     # Match folder path containing keywords
# BLACKLIST_NAME_INCLUDES = "backup,bak,.tmp"                # Match file name containing keywords
# BLACKLIST_PATH_INCLUDES = "temp,cache"                     # Match full path containing keywords
# WHITELIST_DIR_INCLUDES = "public,shared"                   # Match folder path containing keywords
# WHITELIST_NAME_INCLUDES = "readme,license"                 # Match file name containing keywords
# WHITELIST_PATH_INCLUDES = "docs,assets"                    # Match full path containing keywords
# EXCEPT_DIR_INCLUDES = "test,debug"                         # Match folder path containing keywords
# EXCEPT_NAME_INCLUDES = "log,tmp"                           # Match file name containing keywords
# EXCEPT_PATH_INCLUDES = "staging,dev"                       # Match full path containing keywords
# #
# # Union Logic (OR):
# # - PREFIX and INCLUDES are evaluated together (any match triggers action)
# # - Multiple keywords in INCLUDES are OR-ed (any keyword match triggers)
# # Example: BLACKLIST_PREFIX="/admin" + BLACKLIST_DIR_INCLUDES="private,secret"
# #   → Matches: /admin/file.txt (prefix) OR /test/private/file.txt (dir includes) OR /test/secret/file.txt (dir includes)
# #
# # Matching Examples:
# # 1. BLACKLIST_DIR_INCLUDES = "private"
# #    → Blocks: /test/private/file.txt (dirPath "/test/private" contains "private")
# #
# # 2. BLACKLIST_NAME_INCLUDES = "backup"
# #    → Blocks: /test/backup.zip (fileName "backup.zip" contains "backup")
# #
# # 3. BLACKLIST_PATH_INCLUDES = "temp"
# #    → Blocks: /test/temp/file.txt (fullPath contains "temp")
# #    → Blocks: /test/file_temp.txt (fullPath contains "temp")
# #
# # 4. BLACKLIST_PREFIX = "/admin" + BLACKLIST_DIR_INCLUDES = "secret"
# #    → Blocks: /admin/file.txt (prefix match)
# #    → Blocks: /test/secret/file.txt (dir includes match)
# #    → Union logic: either match is sufficient
#
# # ═══════════════════════════════════════════════════════════════
# # Path Filtering System - Priority & Action Reference
# # ═══════════════════════════════════════════════════════════════
# #
# # Priority Order (evaluated in this sequence):
# # 1. BLACKLIST (highest priority) - matches prefix → apply actions
# # 2. WHITELIST (second priority) - matches prefix → apply actions
# # 3. EXCEPT (third priority) - does NOT match prefix → apply actions (inverse logic)
# # 4. Default - no match → use global *_CHECK settings
# #
# # Available Actions (comma-separated, multiple allowed except for block/asis):
# # ┌─────────────────┬──────────────────────────────────────────────────────┐
# # │ Action          │ Description                                          │
# # ├─────────────────┼──────────────────────────────────────────────────────┤
# # │ block           │ Deny access (403). Cannot combine with other actions │
# # │ skip-sign       │ Skip sign parameter verification                     │
# # │ skip-hash       │ Skip hashSign parameter verification                 │
# # │ skip-worker     │ Skip workerSign parameter verification               │
# # │ skip-origin     │ Skip origin binding verification                     │
# # │ asis            │ Keep original behavior. Cannot combine with others   │
# # └─────────────────┴──────────────────────────────────────────────────────┘
# #
# # Except Actions (must use -except suffix, inverse matching):
# # ┌─────────────────┬──────────────────────────────────────────────────────┐
# # │ Action          │ Description                                          │
# # ├─────────────────┼──────────────────────────────────────────────────────┤
# # │ block-except    │ Block paths NOT in EXCEPT_PREFIX                     │
# # │ skip-sign-except│ Skip sign check for paths NOT in EXCEPT_PREFIX       │
# # │ skip-hash-except│ Skip hash check for paths NOT in EXCEPT_PREFIX       │
# # │ skip-worker-except│ Skip worker check for paths NOT in EXCEPT_PREFIX   │
# # │ skip-origin-except│ Skip origin binding for paths NOT in EXCEPT_PREFIX │
# # │ asis-except     │ Use original behavior for paths NOT in EXCEPT_PREFIX │
# # └─────────────────┴──────────────────────────────────────────────────────┘
# #
# #
# # Matching Modes (PREFIX vs INCLUDES):
# # ┌─────────────────┬──────────────────────────────────────────────────────┐
# # │ Mode            │ Description                                          │
# # ├─────────────────┼──────────────────────────────────────────────────────┤
# # │ PREFIX          │ Matches path start (e.g., "/admin" matches           │
# # │                 │ "/admin/file.txt" but NOT "/test/admin/file.txt")    │
# # │ DIR_INCLUDES    │ Matches folder path containing keyword              │
# # │                 │ (e.g., "private" matches "/test/private/file.txt")   │
# # │ NAME_INCLUDES   │ Matches file name containing keyword                 │
# # │                 │ (e.g., "backup" matches "/test/backup.zip")          │
# # │ PATH_INCLUDES   │ Matches full path containing keyword                 │
# # │                 │ (e.g., "temp" matches both "/temp/file.txt" and      │
# # │                 │ "/test/file_temp.txt")                               │
# # └─────────────────┴──────────────────────────────────────────────────────┘
# #
# # Evaluation Logic:
# # - PREFIX and INCLUDES are evaluated together (union/OR logic)
# # - Any match (PREFIX OR DIR_INCLUDES OR NAME_INCLUDES OR PATH_INCLUDES) triggers action
# # - Multiple keywords within INCLUDES are OR-ed (e.g., "key1,key2" matches either)
# # - Priority order remains: BLACKLIST > WHITELIST > EXCEPT
# #
# # Examples:
# #
# # Example 1: Block private paths, allow public with reduced verification
# #   BLACKLIST_PREFIX = "/private,/admin"
# #   BLACKLIST_ACTION = "block"
# #   WHITELIST_PREFIX = "/public"
# #   WHITELIST_ACTION = "skip-origin,skip-worker"
# #
# # Example 2: Only allow specific paths, block everything else
# #   EXCEPT_PREFIX = "/allowed,/safe"
# #   EXCEPT_ACTION = "block-except"
# #   # Paths matching /allowed or /safe → normal checks
# #   # All other paths → blocked (403)
# #
# # Example 3: Skip origin binding for all except sensitive paths
# #   EXCEPT_PREFIX = "/sensitive,/private"
# #   EXCEPT_ACTION = "skip-origin-except"
# #   # Paths matching /sensitive or /private → origin binding enforced
# #   # All other paths → origin binding skipped (even when CHECK_ORIGIN is set)
# #
# # Example 4: Complex multi-level filtering
# #   BLACKLIST_PREFIX = "/blocked"
# #   BLACKLIST_ACTION = "block"
# #   WHITELIST_PREFIX = "/media"
# #   WHITELIST_ACTION = "skip-sign,skip-hash"
# #   EXCEPT_PREFIX = "/api,/system"
# #   EXCEPT_ACTION = "asis-except"
# #   # Priority: /blocked → 403
# #   #          /media → skip sign+hash checks
# #   #          All except /api,/system → use original *_CHECK settings
# #          /api,/system → default behavior

#
# # Database Mode for Download Link Cache
# # Options: "d1" (Cloudflare D1 Binding), "d1-rest" (Cloudflare D1 REST API), "custom-pg-rest" (Custom PostgreSQL + PostgREST)
# # If not set, caching is completely disabled (always call AList API)
# DB_MODE = ""
# DOWNLOAD_CACHE_TABLE = "DOWNLOAD_CACHE_TABLE"
# THROTTLE_PROTECTION_TABLE = "THROTTLE_PROTECTION"
# DOWNLOAD_IP_RATELIMIT_TABLE = "DOWNLOAD_IP_RATELIMIT_TABLE"
# IDLE_TIMEOUT = "0"
# DOWNLOAD_LAST_ACTIVE_TABLE = "DOWNLOAD_LAST_ACTIVE_TABLE"
#
# IDLE_TIMEOUT: 如果链接在此时间内未被访问，视为过期
#   - 格式: 数字+单位 (s=秒, m=分钟, h=小时, d=天)
#   - 例如: "30m" (30分钟), "1h" (1小时)
#   - 设置为 "0" 或空字符串关闭此功能
# DOWNLOAD_LAST_ACTIVE_TABLE: 自定义空闲追踪表名，默认 DOWNLOAD_LAST_ACTIVE_TABLE
#
# # ═══════════════════════════════════════════════════════════════
# # ⚠️ Database Table Initialization Control (Performance Optimization)
# # ═══════════════════════════════════════════════════════════════
# #
# # INIT_TABLES controls whether to create database tables before each RPC/SQL batch call
# # Default: "false" (skip table initialization for optimal performance)
# #
# # How it works:
# # - When "true": Worker calls ensureTables() before every unified check
# #                Creates tables if they don't exist (CREATE TABLE IF NOT EXISTS)
# #                Ensures tables are always available but adds overhead
# # - When "false": Worker skips ensureTables() call completely
# #                 Reduces database round-trips and improves response time
# #                 Tables must be created manually before first use
# #
# # Performance Impact:
# # - "false" (recommended): ~10-50ms faster per request (no table check overhead)
# # - "true" (legacy): Safe but slower (adds CREATE TABLE queries to every request)
# #
# # When to use "true":
# # - First deployment (tables don't exist yet)
# # - Table schema changes (need to update table structure)
# # - Development/testing environments
# # - Automatic recovery after database reset
# #
# # When to use "false":
# # - Production environments (tables already exist)
# # - Performance-critical scenarios
# # - After initial deployment is successful
# #
# # Recommended Workflow:
# # 1. First deployment: INIT_TABLES="true" → Creates all tables
# # 2. Verify tables exist: Check D1 dashboard or run SELECT on tables
# # 3. Switch to production: INIT_TABLES="false" → Optimal performance
# # 4. Schema updates: Temporarily set to "true" → Apply changes → Set back to "false"
# #
# # Tables Created (when INIT_TABLES="true"):
# # - DOWNLOAD_CACHE_TABLE (download link cache)
# # - DOWNLOAD_IP_RATELIMIT_TABLE (IP rate limiting)
# # - THROTTLE_PROTECTION (throttle protection)
# #
# # Note: For custom-pg-rest mode, you should still run init.sql manually for stored procedures
# #       INIT_TABLES only creates tables, not functions/procedures
# #
# INIT_TABLES = "false"
#
# # Link Cache TTL - how long to cache download links before re-fetching from AList
# # Format: {number}{unit} where unit is h (hour), m (minute), s (second)
# # Examples: "30m", "1h", "120s"
# # Default: "30m" (1800 seconds)
# LINK_TTL = "30m"
#
# # Cleanup Percentage - probability of triggering cache cleanup per request
# # Range: 0-100 (supports decimals, e.g., "0.1" = 0.1% chance)
# # Default: "1" (1% chance per request)
# # Cleanup removes records older than LINK_TTL * 2
# CLEANUP_PERCENTAGE = "1"
#
# # D1 (Cloudflare D1 Binding) Download Cache - requires DB_MODE="d1"
# # Note: You must also configure d1_databases binding below
# D1_DATABASE_BINDING = "DB"  # Optional, defaults to "DB"
#
# # D1 REST API Download Cache - requires DB_MODE="d1-rest"
# # Use this mode when you cannot use Workers binding (e.g., external API calls)
# D1_ACCOUNT_ID = "your-cloudflare-account-id"
# D1_DATABASE_ID = "your-d1-database-id"
# D1_API_TOKEN = "your-cloudflare-api-token"
#
# # Custom PostgreSQL + PostgREST Download Cache - requires DB_MODE="custom-pg-rest"
# # Use this mode when you have self-hosted PostgreSQL with PostgREST REST API
# # ⚠️ IMPORTANT: You MUST run init.sql on your PostgreSQL database first!
# #   - Creates required tables & stored procedures (see init.sql)
# POSTGREST_URL = "https://your-domain.com/postgrest"  # PostgREST API endpoint (without table name)
# # Note: VERIFY_HEADER and VERIFY_SECRET (already defined above) are used for PostgREST authentication
#
# # ═══════════════════════════════════════════════════════════════
# # Throttle Protection System - Prevent Repeated Requests to Failing Hostnames
# # ═══════════════════════════════════════════════════════════════
# #
# # Purpose: Protect against repeated requests to hostnames that are returning errors
# # (e.g., OneDrive throttling with 429, Google Drive service errors with 503)
# #
# # How it works:
# # 1. When a download URL returns 4xx/5xx, the hostname is marked as "protected"
# # 2. Subsequent requests to that hostname will return the cached error without fetching
# # 3. After the time window expires, requests resume normally
# # 4. If successful, protection is cleared automatically
# #
# # Requirements:
# # - DB_MODE must be set (d1, d1-rest, or custom-pg-rest)
# # - For custom-pg-rest: Run init.sql to create THROTTLE_PROTECTION table and stored procedures
# #
# # Configuration:
# THROTTLE_PROTECT_HOSTNAME = ""  # Comma-separated hostname patterns to protect
#                                  # Examples: "*.sharepoint.com,*.googleapis.com"
#                                  #   - "*.sharepoint.com" matches both "xxx.sharepoint.com" and "sharepoint.com"
#                                  #   - "example.com" matches only "example.com"
#                                  # Default: "" (disabled - no protection)
#
# THROTTLE_TIME_WINDOW = "60s"    # Time window for protection (format: {number}{unit})
#                                  # Units: s (seconds), m (minutes), h (hours)
#                                  # Examples: "30s", "5m", "1h"
#                                  # Default: "60s"
#                                  # After this time, requests will resume to check if service recovered
#
# THROTTLE_PROTECT_HTTP_CODE = "429,500,503"  # Status codes that trigger protection (comma-separated)
#                                             # Provide only the codes that should cause throttle protect writes
#                                             # Example: "500" or "429,500,503"
#                                             # Default: "429,500,503"

# # ═══════════════════════════════════════════════════════════════
# # IP Subnet Rate Limiting (database-backed)
# # ═══════════════════════════════════════════════════════════════
# #
# # WINDOW_TIME = "24h"                  # Counting window per subnet
# # IPSUBNET_WINDOWTIME_LIMIT = "100"    # Max requests per subnet within WINDOW_TIME
# # IPV4_SUFFIX = "/32"                  # IPv4 subnet mask applied before hashing
# # IPV6_SUFFIX = "/60"                  # IPv6 subnet mask applied before hashing
# # BLOCK_TIME = "10m"                   # Additional block duration after hitting the limit
# # PG_ERROR_HANDLE = "fail-closed"      # Use "fail-open" to bypass DB errors gracefully

# # ═══════════════════════════════════════════════════════════════
# # ⚠️ NEW: Cloudflare Rate Limiter (Binding-based, Stateless/Stateful)
# # ═══════════════════════════════════════════════════════════════
# #
# # Purpose: First-layer rate limiting using Cloudflare's native Rate Limiter binding
# # Benefits:
# #   - Ultra-low latency (<10ms, edge-based enforcement)
# #   - Works in both stateless (DB_MODE="") and stateful (DB_MODE set) modes
# #   - Zero database cost for stateless deployments
# #   - Can be used as additional protection layer when combined with DB rate limiting
# #
# # How it works:
# # 1. Request arrives → CF Rate Limiter checks (based on IP subnet SHA256)
# # 2. If limit exceeded → Return 429 immediately (no DB queries)
# # 3. If allowed → Continue to DB rate limiting (if DB_MODE set) or handle request
# #
# # Dual Protection (Stateful Mode):
# # - CF Rate Limiter: Blocks obvious abuse at edge (e.g., 10 req/10s)
# # - DB Rate Limiting: Fine-grained control (e.g., 100 req/24h)
# # - Advantages: CF absorbs high-frequency attacks, DB handles long-term limits
# #
# # Requirements:
# # - Must configure [[rate_limit]] binding in wrangler.toml (see below)
# # - ENABLE_CF_RATELIMITER must be "true" to activate
# # - Binding validation enforced at startup (throws error if binding not found)
# #
# # Configuration:
# ENABLE_CF_RATELIMITER = "false"      # Enable Cloudflare Rate Limiter binding
#                                       # Default: "false" (disabled)
#                                       # Set to "true" to enable first-layer rate limiting
#                                       # Works in both stateless and stateful modes
#                                       # If enabled but binding not found → startup error
#
# CF_RATELIMITER_BINDING = "CF_RATE_LIMITER"  # Rate Limiter binding name
#                                              # Default: "CF_RATE_LIMITER"
#                                              # Must match [[rate_limit]].binding below
#                                              # Change if using custom binding name
#
# # Limiting Key Strategy:
# # - Uses SHA256(IP subnet) as rate limiting key
# # - Respects IPV4_SUFFIX and IPV6_SUFFIX settings (same as DB rate limiting)
# # - Example: IPV4_SUFFIX="/24" → all IPs in 192.168.1.0/24 share the same limit
# #
# # Error Handling:
# # - Binding not found when enabled → Throws startup error
# # - Rate limit exceeded → Returns 429 with Retry-After: 60 header
# # - CF Rate Limiter failure → fail-open (continues to DB or handles request)
# #
# # Example Configuration (Stateless Mode):
# #   ENABLE_CF_RATELIMITER = "true"
# #   CF_RATELIMITER_BINDING = "CF_RATE_LIMITER"
# #   DB_MODE = ""  # No database, pure edge rate limiting
# #   IPV4_SUFFIX = "/24"
# #   IPV6_SUFFIX = "/60"
# #
# # Example Configuration (Stateful Dual Protection):
# #   ENABLE_CF_RATELIMITER = "true"
# #   CF_RATELIMITER_BINDING = "CF_RATE_LIMITER"
# #   DB_MODE = "custom-pg-rest"
# #   WINDOW_TIME = "24h"
# #   IPSUBNET_WINDOWTIME_LIMIT = "100"  # 100 requests per 24h (DB layer)
# #   # CF Rate Limiter configured in binding: 10 requests per 10s (edge layer)

# D1 Database Binding (for DB_MODE="d1")
# Uncomment and configure this section if using D1 binding mode
# [[d1_databases]]
# binding = "DB"  # Must match D1_DATABASE_BINDING env var (or use default "DB")
# database_name = "alist-cache-db"
# database_id = "your-d1-database-id"

# ═══════════════════════════════════════════════════════════════
# ⚠️ NEW: Cloudflare Rate Limiter Binding (for ENABLE_CF_RATELIMITER="true")
# ═══════════════════════════════════════════════════════════════
#
# Uncomment and configure this section if enabling CF Rate Limiter
# The rate limit rules (period, limit) are configured here, NOT in environment variables
# Documentation: https://developers.cloudflare.com/workers/runtime-apis/bindings/rate-limit/
#
# [[rate_limit]]
# binding = "CF_RATE_LIMITER"  # Must match CF_RATELIMITER_BINDING env var
#
# # Simple Algorithm (Fixed Window)
# # Example: 10 requests per 10 seconds
# simple = { period = 10, limit = 10 }
#
# # Alternative: Sliding Window Algorithm (More accurate)
# # Example: 100 requests per 60 seconds (sliding window)
# # sliding_window = { period = 60, limit = 100 }
#
# # Notes:
# # - period: Time window in seconds (max 86400 = 24h)
# # - limit: Maximum requests per period per key (IP subnet SHA256)
# # - Choose simple for lower latency, sliding_window for more accurate enforcement
# # - These parameters cannot be changed via environment variables
# # - Must redeploy worker to change rate limit rules
#
# # Recommended Configurations:
# #
# # Light Protection (Edge layer):
# #   simple = { period = 10, limit = 20 }
# #   # 20 requests per 10 seconds = ~2 req/s burst
# #
# # Medium Protection (Edge layer):
# #   simple = { period = 10, limit = 10 }
# #   # 10 requests per 10 seconds = 1 req/s sustained
# #
# # Heavy Protection (Edge + DB layer):
# #   simple = { period = 10, limit = 5 }
# #   # Edge: 5 req/10s, DB: 100 req/24h (configure in WINDOW_TIME/IPSUBNET_WINDOWTIME_LIMIT)

# ═══════════════════════════════════════════════════════════════
# ⚠️ NEW: Fair Upstream Queue - Concurrent Request Limiting per Upstream Host
# ═══════════════════════════════════════════════════════════════
#
# Purpose: Limit concurrent upstream fetch requests per hostname pattern to prevent
#          overloading upstream sources (e.g., SharePoint, OneDrive, Google Drive)
#
# Key Concepts:
# - **Slot Pool**: Database-driven pool of slots (1..N) per hostname pattern
# - **Per-IP Fairness**: Single IP subnet cannot monopolize all slots
# - **Queue Mechanism**: Requests wait for available slot instead of immediate rejection
# - **Short Occupation**: Slots held ONLY during upstream fetch (TTFB ~1-3s), NOT during file download
#
# How it works:
# 1. Request arrives → Hostname matches FAIR_QUEUE_HOST_PATTERNS
# 2. Worker tries to acquire slot from pool (max concurrent = FAIR_QUEUE_GLOBAL_LIMIT)
# 3. If slot available → Acquire → Fetch upstream → Release immediately
# 4. If no slot available → Wait in queue (up to FAIR_QUEUE_WAIT_TIMEOUT_MS)
# 5. If per-IP limit reached → Return 429 immediately
#
# Slot Occupancy Timeline:
#   [Request] → [Acquire slot] → [await fetch(upstream)] → [Got Response headers] → [Release slot] → [Stream file 2min]
#                ↑_____________ Slot held ~1-3s (TTFB only) _____________↑
#
# Database Mode Requirements:
# ┌──────────────────┬─────────────────────┬────────────────────────────────┐
# │ DB Mode          │ Table Creation      │ Queue Implementation           │
# ├──────────────────┼─────────────────────┼────────────────────────────────┤
# │ PostgreSQL       │ Manual (init.sql)   │ Single-attempt RPC + Worker wait │
# │ D1               │ Auto (INIT_TABLES)  │ Single-attempt SQL + Worker wait │
# │ D1-REST          │ Auto (INIT_TABLES)  │ Single-attempt SQL + Worker wait │
# └──────────────────┴─────────────────────┴────────────────────────────────┘
#
# PostgreSQL Setup:
#   1. Run init.sql to create:
#      - Table: upstream_slot_pool
#      - Functions: func_try_acquire_slot, func_release_fair_slot, func_cleanup_zombie_slots
#   2. INIT_TABLES has no effect (PostgREST doesn't support auto-table creation)
#
# D1/D1-REST Setup:
#   1. First deployment: INIT_TABLES="true" → Creates upstream_slot_pool table
#   2. Subsequent requests: INIT_TABLES="false" → Table persists, queue functions always available
#
# Relationship with Throttle Protection:
# ┌────────────────┬────────────────┬──────────────────────────────────┐
# │ State          │ Fair Queue     │ Throttle Protection              │
# ├────────────────┼────────────────┼──────────────────────────────────┤
# │ Normal         │ Limits slots   │ Not active                       │
# │ Upstream Error │ Not triggered  │ Marks host as protected (503)    │
# │ Protection Win │ Not entered    │ Unified check returns 503 early  │
# └────────────────┴────────────────┴──────────────────────────────────┘
# Combined Behavior:
#   - Normal: Fair Queue limits concurrency proactively
#   - Error: Throttle Protection circuit-breaks, blocks requests BEFORE queue
#   - Recovery: Protection window expires → Fair Queue resumes limiting
#
# Configuration:
#
# FAIR_QUEUE_ENABLED = "false"       # Enable fair queue (default: false)
#                                     # Requires DB_MODE to be set
#                                     # Requires FAIR_QUEUE_HOST_PATTERNS to be non-empty
#
# FAIR_QUEUE_HOST_PATTERNS = ""      # Comma-separated hostname patterns to protect
#                                     # Supports wildcards: "*.sharepoint.com,*.onedrive.com"
#                                     # Examples:
#                                     #   "*.sharepoint.com" → matches "contoso-my.sharepoint.com"
#                                     #   "example.com" → matches only "example.com"
#                                     # Default: "" (disabled)
#
# FAIR_QUEUE_GLOBAL_LIMIT = "5"      # Max concurrent slots per hostname pattern
#                                     # Default: 5
#                                     # Recommendation: Start with 5, adjust based on upstream limits
#                                     # Example: SharePoint often limits to 5-10 concurrent connections
#
# FAIR_QUEUE_PER_IP_LIMIT = "1"      # Max concurrent slots per IP subnet
#                                     # Default: 1
#                                     # Prevents single IP/NAT from monopolizing all slots
#                                     # Recommendation: Keep at 1 for fairness, increase to 2-3 if needed
#
# FAIR_QUEUE_MAX_WAITERS_PER_IP = "3" # Max pending queue waiters per hostname × IP subnet
#                                     # Default: 3
#                                     # Requests beyond this depth are rejected immediately with 429
#                                     # Helps prevent IDM-style burst traffic from overwhelming the queue
#
# FAIR_QUEUE_WAIT_TIMEOUT_MS = "15000"  # Max queue wait time in milliseconds
#                                        # Default: 15000 (15 seconds)
#                                        # Leaves 15s buffer for 30s Worker wall-time limit
#                                        # If exceeded → Returns 503 Queue Timeout
#
# FAIR_QUEUE_ZOMBIE_TIMEOUT_SECONDS = "30"  # Zombie slot auto-reclaim timeout
#                                            # Default: 30 seconds
#                                            # Slots stuck in "locked" state > this duration are released
#                                            # Prevents leaks from Worker crashes/exceptions

# FAIR_QUEUE_QUEUE_DEPTH_ZOMBIE_TTL_SECONDS = "20"  # Queue depth zombie timeout
#                                                    # Default: 20 seconds
#                                                    # Auto-resets stale waiter counts when Worker cleanup fails
#                                                    # Increase if users see premature queue resets, decrease to evict faster
#
# FAIR_QUEUE_POLL_INTERVAL_MS = "200"  # Worker-side polling interval between slot attempts (milliseconds)
#                                       # Default: 200ms
#                                       # Tradeoff: Lower = more responsive, Higher = less DB pressure
#
# FAIR_QUEUE_MIN_SLOT_HOLD_MS = "800"   # Minimum slot hold time (ms) to approximate QPS
#                                       # Default: 800ms (with 4 slots ≈ 5 QPS to upstream)
#                                       # Set to 0 to disable hold-and-release behavior
#
# FAIR_QUEUE_TABLE_NAME = "upstream_slot_pool"  # Fair queue table name
#                                                # Default: upstream_slot_pool
#                                                # Only change if table name conflicts exist
#
# FAIR_QUEUE_IP_COOLDOWN_SECONDS = "3"  # Cooldown before same IP can re-acquire slot
#                                       # Default: 3 seconds (set to 0 to disable cooldown logic)
#
# Error Responses:
# ┌─────────────────────────┬──────────┬─────────────┬───────────────────────────────┐
# │ Condition               │ Status   │ Retry-After │ Meaning                       │
# ├─────────────────────────┼──────────┼─────────────┼───────────────────────────────┤
# │ Per-IP limit reached    │ 429      │ 60s         │ IP has max concurrent slots   │
# │ Queue timeout           │ 503      │ 60s         │ Waited 15s, no slot available │
# │ Upstream throttled      │ 503      │ Varies      │ Throttle Protection active    │
# └─────────────────────────┴──────────┴─────────────┴───────────────────────────────┘
#
# Example Configurations:
#
# Example 1: Protect SharePoint with conservative limits
#   FAIR_QUEUE_ENABLED = "true"
#   FAIR_QUEUE_HOST_PATTERNS = "*.sharepoint.com"
#   FAIR_QUEUE_GLOBAL_LIMIT = "5"
#   FAIR_QUEUE_PER_IP_LIMIT = "1"
#   FAIR_QUEUE_MAX_WAITERS_PER_IP = "3"
#   FAIR_QUEUE_MAX_WAITERS_PER_IP = "3"
#   DB_MODE = "custom-pg-rest"
#   # Result: Max 5 concurrent SharePoint connections, 1 per IP, queues if exceeded
#
# Example 2: Multiple upstream sources with higher limits
#   FAIR_QUEUE_ENABLED = "true"
#   FAIR_QUEUE_HOST_PATTERNS = "*.sharepoint.com,*.onedrive.com,*.googleapis.com"
#   FAIR_QUEUE_GLOBAL_LIMIT = "10"
#   FAIR_QUEUE_PER_IP_LIMIT = "2"
#   FAIR_QUEUE_MAX_WAITERS_PER_IP = "4"
#   DB_MODE = "d1"
#   INIT_TABLES = "true"  # First deployment only
#   # Result: 10 concurrent connections per hostname, 2 per IP
#
# Example 3: Combined with Throttle Protection
#   FAIR_QUEUE_ENABLED = "true"
#   FAIR_QUEUE_HOST_PATTERNS = "*.sharepoint.com"
#   FAIR_QUEUE_GLOBAL_LIMIT = "5"
#   THROTTLE_PROTECT_HOSTNAME = "*.sharepoint.com"
#   THROTTLE_TIME_WINDOW = "60s"
#   # Result: Normal state → Queue limits concurrency
#   #         Error state → Throttle blocks requests early
#
# Troubleshooting:
#
# Problem: All requests get 503 Queue Timeout
# Diagnosis:
#   - Check FAIR_QUEUE_GLOBAL_LIMIT (may be too low)
#   - Check upstream TTFB (if >5s, slots stay locked longer)
#   - Check zombie cleanup (FAIR_QUEUE_ZOMBIE_TIMEOUT_SECONDS may be too high)
# Solution:
#   - Increase FAIR_QUEUE_GLOBAL_LIMIT to 10-20
#   - Decrease FAIR_QUEUE_ZOMBIE_TIMEOUT_SECONDS to 15-20
#
# Problem: Single IP can't download multiple files in parallel
# Diagnosis:
#   - FAIR_QUEUE_PER_IP_LIMIT=1 blocks parallel downloads from same IP
# Solution:
#   - Increase FAIR_QUEUE_PER_IP_LIMIT to 2-3
#   - Ensure FAIR_QUEUE_GLOBAL_LIMIT is also increased proportionally
#
# Problem: Fair Queue not working
# Diagnosis:
#   - Check FAIR_QUEUE_ENABLED="true"
#   - Check FAIR_QUEUE_HOST_PATTERNS is non-empty
#   - Check DB_MODE is set (d1/d1-rest/custom-pg-rest)
#   - PostgreSQL: Verify init.sql was run
#   - D1: Verify INIT_TABLES="true" was used at least once
# Solution:
#   - Enable all required settings
#   - Check worker logs for "[Fair Queue]" messages

# For local development, create a .dev.vars file with:
# ADDRESS=https://your-alist-server.com
# TOKEN=your-hmac-token
# WORKER_ADDRESS=https://your-worker.workers.dev
